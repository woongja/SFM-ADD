# Conformer-TCM Balanced Training Configuration
# All augmentation types in each mini-batch

model:
  name: conformertcm
  emb_size: 144
  heads: 4
  kernel_size: 31
  num_encoders: 4

data:
  name: data_utils_balance  # Use balanced sampling with online augmentation
  n_mels: 64
  n_fft: 512
  hop_length: 160
  win_length: 400
  fmin: 20
  fmax: 7600
  mean_norm: true
  std_norm: true

# Balanced Training Strategy:
# Each mini-batch contains:
#   - 10 augmentation types Ã— 2 (bonafide + spoof) = 20 samples
#   - 2 clean (1 bonafide + 1 spoof) = 2 samples
#   Total = 22 samples per batch
#
# This ensures:
#   1. All augmentation types are present in every batch
#   2. Balanced bonafide/spoof ratio (1:1)
#   3. Model sees diverse augmentation in each update
